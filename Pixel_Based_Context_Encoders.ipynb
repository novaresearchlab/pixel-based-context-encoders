{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndeG_-6pnXpo"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "\n",
    "from torchvision.datasets import STL10\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class ContextEncoder():\n",
    "    def __init__(self, mask_name):\n",
    "        print(\"Model initializing..\")\n",
    "        self.img_rows = 96\n",
    "        self.img_cols = 96\n",
    "        self.mask_height = 48   \n",
    "        self.mask_width = 48\n",
    "        self.channels = 3\n",
    "        self.mask_name = mask_name\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.missing_shape = (self.mask_height, self.mask_width, self.channels)\n",
    "        \n",
    "        #download = True if no dataset is downloaded\n",
    "        self.X_train = STL10(root='drive/My Drive/ContextEncoder/dataset', split='unlabeled', download=True)\n",
    "        self.X_train = np.moveaxis(self.X_train.data[:10000], 1, 3)\n",
    "\n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=self.optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates the missing\n",
    "        # part of the image\n",
    "        masked_img = Input(shape=self.img_shape)\n",
    "        gen_missing = self.generator(masked_img)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines\n",
    "        # if it is generated or if it is a real image\n",
    "        valid = self.discriminator(gen_missing)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model(masked_img , [gen_missing, valid])\n",
    "        self.combined.compile(loss=['mse', 'binary_crossentropy'],\n",
    "            loss_weights=[0.999, 0.001],\n",
    "            optimizer=self.optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # Encoder\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Conv2D(512, kernel_size=1, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # Decoder\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        #model.add(UpSampling2D())\n",
    "        #model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "        #model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation('tanh'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        masked_img = Input(shape=self.img_shape)\n",
    "        gen_missing = model(masked_img)\n",
    "        return Model(masked_img, gen_missing)   #inputs: masked images\n",
    "                                                #outputs: generated missings\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=self.missing_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.missing_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def maskn(self, imgs, n):   #mask function without empty areas\n",
    "        num = len(imgs)\n",
    "        masked_imgs = np.empty_like(imgs)\n",
    "        missing_parts = np.empty((num, self.mask_height, self.mask_width, self.channels))\n",
    "\n",
    "        submask = np.ones((2*n, 2*n, self.channels))\n",
    "        submask[n:,n:] = 0\n",
    "\n",
    "        N = self.img_rows//(2*n)    # how many submask is there in a row/column\n",
    "\n",
    "        mask = np.concatenate(N*[submask], axis=0)\n",
    "        mask = np.concatenate(N*[mask], axis=1)\n",
    "\n",
    "        for i, img in enumerate(imgs):\n",
    "            masked = np.einsum('ijk,ijk->ijk', img, mask)\n",
    "\n",
    "            missing_part = img[np.where(mask==0)]\n",
    "            missing_part = missing_part.reshape((self.mask_height, self.mask_width, self.channels))\n",
    "\n",
    "            masked_imgs[i] = masked\n",
    "            missing_parts[i] = missing_part\n",
    "\n",
    "        return masked_imgs, missing_parts\n",
    "    \n",
    "    def total_mask(self, imgs, n):      #masked images with white areas\n",
    "        num = len(imgs)\n",
    "        masked_imgs = np.empty_like(imgs)\n",
    "        missing_parts = np.empty((num, self.mask_height, self.mask_width, self.channels))\n",
    "        \n",
    "        #Mask for image\n",
    "        submask = np.ones((2*n, 2*n, self.channels))\n",
    "        submask[n:,n:] = 0\n",
    "        N = self.img_rows//(2*n)    # how many submask is there in a row/column\n",
    "\n",
    "        mask = np.concatenate(N*[submask], axis=0)\n",
    "        mask = np.concatenate(N*[mask], axis=1)\n",
    "\n",
    "        #Mask for missing parts\n",
    "        reverse_mask = 1 - mask\n",
    "\n",
    "        for i, img in enumerate(imgs):\n",
    "            masked = np.einsum('ijk,ijk->ijk', img, mask)\n",
    "            missing_part = np.einsum('ijk, ijk->ijk', img, reverse_mask)\n",
    "\n",
    "            masked_imgs[i] = masked\n",
    "            missing_parts[i] = missing_part\n",
    "\n",
    "        return masked_imgs, missing_parts\n",
    "\n",
    "    def unmask(self, masked, missing, mask_n):\n",
    "        for i in range(0, self.mask_height, mask_n):\n",
    "            for j in range(0, self.mask_width, mask_n):\n",
    "                masked[2*i+mask_n:2*(i+mask_n), 2*j+mask_n:2*(j+mask_n), :] = missing[i:i+mask_n, j:j+mask_n, :]\n",
    "        return masked\n",
    "    \n",
    "    def total_unmask(self, masked, missing, mask_n):\n",
    "        submask = np.ones((2*mask_n, 2*mask_n, self.channels))\n",
    "        submask[mask_n:,mask_n:] = 0\n",
    "        N = self.img_rows//(2*mask_n)    # how many submask is there in a row/column\n",
    "\n",
    "        mask = np.concatenate(N*[submask], axis=0)\n",
    "        mask = np.concatenate(N*[mask], axis=1)\n",
    "\n",
    "        #Mask for missing parts\n",
    "        reverse_mask = 1 - mask\n",
    "\n",
    "        masked = np.einsum('ijk,ijk->ijk', masked, mask)\n",
    "        missing = np.einsum('ijk, ijk->ijk', missing, reverse_mask)\n",
    "    \n",
    "        return np.add(masked, missing)\n",
    "    \n",
    "    def train(self, epochs, batch_size=128, sample_interval=50, mask_n=1):    \n",
    "        # Rescale -1 to 1\n",
    "        train_set = self.X_train / 127.5 - 1\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        d_losses = []\n",
    "        g_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, train_set.shape[0], batch_size)\n",
    "            imgs = train_set[idx]\n",
    "\n",
    "            masked_imgs, missing_parts = self.maskn(imgs, mask_n)\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_missing = self.generator.predict(masked_imgs)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(missing_parts, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_missing, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(masked_imgs, [missing_parts, valid])\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0], g_loss[1]))\n",
    "\n",
    "            if epoch % 1000 == 0:\n",
    "                # Plot the progress\n",
    "                file = open(\"drive/My Drive/ContextEncoder/%s/metrics.txt\" % (self.mask_name), \"w\")\n",
    "                file.write(\"[Discriminative loss: %f]\\n[Generative loss: %f]\" % (d_loss[0], g_loss[0]))\n",
    "                file.close()\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                d_losses.append(d_loss[0])\n",
    "                g_losses.append(g_loss[0])\n",
    "\n",
    "        for i in [5, 8, 82, 93, 115, 116, 121, 135, 153, 166,\n",
    "            183, 244, 249, 305, 343, 375, 419, 428, 512, 639,\n",
    "            691, 745, 746, 825, 832]:\n",
    "            self.sample_images(train_set, mask_n=mask_n, col=i)\n",
    "        return d_losses, g_losses\n",
    "\n",
    "    def sample_images(self, imgs, mask_n, col=0):\n",
    "        masked_imgs, missing_parts = self.maskn([imgs[col]], mask_n)\n",
    "        gen_missing = self.generator.predict(masked_imgs)\n",
    "\n",
    "        filled_in = imgs[col].copy()\n",
    "\n",
    "        filled_in = 0.5 * filled_in + 0.5\n",
    "        gen_missing = 0.5 * gen_missing + 0.5\n",
    "\n",
    "        plt.figure()\n",
    "        filled_in = self.unmask(filled_in, gen_missing[0], mask_n=mask_n)\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(filled_in)\n",
    "        plt.savefig(\"drive/My Drive/ContextEncoder/%s/images%d/%d.png\" % (self.mask_name, mask_n, col), bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "    def save_masks(self, upto):\n",
    "        mask_n = 1\n",
    "        blank = np.ones((1,self.img_rows, self.img_cols, self.channels))\n",
    "        while mask_n < upto:\n",
    "            mask = self.maskn(blank, mask_n)\n",
    "            plt.imshow(mask[0][0])\n",
    "            plt.axis(\"off\")\n",
    "            plt.savefig(\"drive/My Drive/ContextEncoder/masks/mask_%d.png\" % mask_n, bbox_inches='tight', pad_inches=0)\n",
    "            mask_n *= 2\n",
    "\n",
    "    def save_original(self, img_list):\n",
    "        for i in img_list:\n",
    "            plt.figure()\n",
    "            plt.axis('off')\n",
    "            plt.imshow(self.X_train[i])\n",
    "            plt.savefig(\"drive/My Drive/ContextEncoder/original/%d.png\" % i, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMmzYHO2MI3F"
   },
   "outputs": [],
   "source": [
    "def model(batch_size=64, sample_interval=1, train_list=[(1, 15001)], mask_name=\"1x1\"):\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    context_encoder = ContextEncoder(mask_name)\n",
    "\n",
    "    for n, epoch in train_list:\n",
    "        d_losses_partial, g_losses_partial = context_encoder.train(epochs=epoch, batch_size=batch_size, sample_interval=sample_interval, mask_n=n)\n",
    "        \n",
    "        d_losses = np.concatenate((d_losses, d_losses_partial))\n",
    "        g_losses = np.concatenate((g_losses, g_losses_partial))\n",
    "    \n",
    "    plt.plot(np.array(range(0, sample_interval*len(g_losses), sample_interval)), g_losses, label='generative loss')\n",
    "    plt.legend()\n",
    "    plt.title('Losses')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.savefig(\"drive/My Drive/ContextEncoder/%s/Losses_gen.png\" %(mask_name), bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(np.array(range(0, sample_interval*len(d_losses), sample_interval)), d_losses, label='discriminative loss')\n",
    "    plt.legend()\n",
    "    plt.title('Losses')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.savefig(\"drive/My Drive/ContextEncoder/%s/Losses_disc.png\" %mask_name, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fTD3eEx6zSGm",
    "outputId": "64deb08b-ab91-48bf-8170-e788a5ea944c"
   },
   "outputs": [],
   "source": [
    "model( train_list=[(1, 1001)], mask_name=\"1x1\")\n",
    "model( train_list=[(1, 1001), (2, 1001)], mask_name=\"1x1 + 2x2\")\n",
    "model( train_list=[(1, 1001), (2, 1001), (4, 1001)], mask_name=\"1x1 + 2x2 + 4x4\")\n",
    "model( train_list=[(1, 1001), (2, 1001), (4, 1001), (8, 1001)], mask_name=\"1x1 + 2x2 + 4x4 + 8x8\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pixel Based Context Encoders",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
